{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e966a723",
   "metadata": {},
   "source": [
    "# 1D harmonic oscillator physics-informed neural network (PINN)\n",
    "\n",
    "This notebook contains the code to reproduce the plots presented in my blog post [\"So, what is a physics-informed neural network?\"](https://benmoseley.blog/my-research/so-what-is-a-physics-informed-neural-network/). \n",
    "\n",
    "Please read the post for more details!\n",
    "\n",
    "## Problem overview\n",
    "\n",
    "The example problem we solve here is the 1D damped harmonic oscillator:\n",
    "$$\n",
    "m \\dfrac{d^2 x}{d t^2} + \\mu \\dfrac{d x}{d t} + kx = 0~,\n",
    "$$\n",
    "with the initial conditions\n",
    "$$\n",
    "x(0) = 1~~,~~\\dfrac{d x}{d t} = 0~.\n",
    "$$\n",
    "We will focus on solving the problem for the under-damped state, i.e. when \n",
    "$$\n",
    "\\delta < \\omega_0~,~~~~~\\mathrm{with}~~\\delta = \\dfrac{\\mu}{2m}~,~\\omega_0 = \\sqrt{\\dfrac{k}{m}}~.\n",
    "$$\n",
    "This has the following exact solution:\n",
    "$$\n",
    "x(t) = e^{-\\delta t}(2 A \\cos(\\phi + \\omega t))~,~~~~~\\mathrm{with}~~\\omega=\\sqrt{\\omega_0^2 - \\delta^2}~.\n",
    "$$\n",
    "\n",
    "This problem was inspired by the following blog post: https://beltoforion.de/en/harmonic_oscillator/.\n",
    "\n",
    "## Workflow overview\n",
    "\n",
    ">First we will train a standard neural network to interpolate a small part of the solution, using some observed training points from the solution.\n",
    "\n",
    ">Next, we will train a PINN to extrapolate the full solution outside of these training points by penalising the underlying differential equation in its loss function.\n",
    "\n",
    "\n",
    "## Environment set up\n",
    "\n",
    "We train the PINN using PyTorch, using the following environment set up:\n",
    "```bash\n",
    "\n",
    "conda create -n pinn python=3\n",
    "conda activate pinn\n",
    "conda install jupyter numpy matplotlib\n",
    "conda install pytorch torchvision torchaudio -c pytorch\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac19c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif_PIL(outfile, files, fps=5, loop=0):\n",
    "    \"Helper function for saving GIFs\"\n",
    "    imgs = [Image.open(file) for file in files]\n",
    "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
    "    \n",
    "def oscillator(d, w0, x):\n",
    "    \"\"\"Defines the analytical solution to the 1D underdamped harmonic oscillator problem. \n",
    "    Equations taken from: https://beltoforion.de/en/harmonic_oscillator/\"\"\"\n",
    "    assert d < w0\n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*x)\n",
    "    sin = torch.sin(phi+w*x)\n",
    "    exp = torch.exp(-d*x)\n",
    "    y  = exp*2*A*cos\n",
    "    return y\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a connected network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee01e6",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "\n",
    "> First, we generate some training data from a small part of the true analytical solution.\n",
    "\n",
    "For this problem, we use $\\delta=2$, $\\omega_0=20$, and try to learn the solution over the domain $x\\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, w0 = 2, 20\n",
    "\n",
    "# get the analytical solution over the full domain\n",
    "x = torch.linspace(0,1,500).view(-1,1)\n",
    "y = oscillator(d, w0, x).view(-1,1)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# slice out a small number of points from the LHS of the domain\n",
    "x_data = x[0:200:20]\n",
    "y_data = y[0:200:20]\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=\"Exact solution\")\n",
    "plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cd505",
   "metadata": {},
   "source": [
    "## Normal neural network\n",
    "\n",
    "> Next, we train a standard neural network (fully connected network) to fit these training points.\n",
    "\n",
    ">We find that the network is able to fit the solution very closely in the vicinity of the training points, but does not learn an accurate solution outside of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847195e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_result(x,y,x_data,y_data,yh,xp=None):\n",
    "    \"Pretty plot training results\"\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
    "    plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n",
    "    plt.scatter(x_data, y_data, s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
    "    if xp is not None:\n",
    "        plt.scatter(xp, -0*torch.ones_like(xp), s=60, color=\"tab:green\", alpha=0.4, \n",
    "                    label='Physics loss training locations')\n",
    "    l = plt.legend(loc=(1.01,0.34), frameon=False, fontsize=\"large\")\n",
    "    plt.setp(l.get_texts(), color=\"k\")\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.text(1.065,0.7,\"Training step: %i\"%(i+1),fontsize=\"xx-large\",color=\"k\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    \n",
    "    # train standard neural network to fit training data\n",
    "    torch.manual_seed(123)\n",
    "    model = FCN(1,1,32,3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    files = []\n",
    "    for i in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        yh = model(x_data)\n",
    "        loss = torch.mean((yh-y_data)**2)# use mean squared error\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # plot the result as training progresses\n",
    "        if (i+1) % 10 == 0:     \n",
    "            yh = model(x).detach()\n",
    "            \n",
    "            plot_result(x,y,x_data,y_data,yh)\n",
    "            \n",
    "            file = f\"{tmpdir}/nn_{i+1:08}.png\"\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "            files.append(file)\n",
    "        \n",
    "            if (i+1) % 500 == 0: plt.show()\n",
    "            else: plt.close(\"all\")\n",
    "                \n",
    "    save_gif_PIL(\"nn.gif\", files, fps=20, loop=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d57ca",
   "metadata": {},
   "source": [
    "## PINN\n",
    "\n",
    "> Finally, we add the underlying differential equation (\"physics loss\") to the loss function. \n",
    "\n",
    "The physics loss aims to ensure that the learned solution is consistent with the underlying differential equation. This is done by penalising the residual of the differential equation over a set of locations sampled from the domain.\n",
    "\n",
    "Here we evaluate the physics loss at 30 points uniformly spaced over the problem domain $([0,1])$. We can calculate the derivatives of the network solution with respect to its input variable at these points using `pytorch`'s autodifferentiation features, and can then easily compute the residual of the differential equation using these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc42d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n",
    "mu, k = 2*d, w0**2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = FCN(1,1,32,3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "files = []\n",
    "\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "\n",
    "    for i in range(20000):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute the \"data loss\"\n",
    "        yh = model(x_data)\n",
    "        loss1 = torch.mean((yh-y_data)**2)# use mean squared error\n",
    "        \n",
    "        # compute the \"physics loss\"\n",
    "        yhp = model(x_physics)\n",
    "        dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
    "        dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
    "        physics = dx2 + mu*dx + k*yhp# computes the residual of the 1D harmonic oscillator differential equation\n",
    "        loss2 = (1e-4)*torch.mean(physics**2)\n",
    "        \n",
    "        # backpropagate joint loss\n",
    "        loss = loss1 + loss2# add two loss terms together\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # plot the result as training progresses\n",
    "        if (i+1) % 150 == 0: \n",
    "            \n",
    "            yh = model(x).detach()\n",
    "            xp = x_physics.detach()\n",
    "            \n",
    "            plot_result(x,y,x_data,y_data,yh,xp)\n",
    "            \n",
    "            file = f\"{tmpdir}/pinn_{i+1:08}.png\"\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "            files.append(file)\n",
    "            \n",
    "            if (i+1) % 6000 == 0: plt.show()\n",
    "            else: plt.close(\"all\")\n",
    "                \n",
    "    save_gif_PIL(\"pinn.gif\", files, fps=20, loop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026fd49",
   "metadata": {},
   "source": [
    "![nn](nn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faab764",
   "metadata": {},
   "source": [
    "\n",
    "![pinn](pinn.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aff521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
